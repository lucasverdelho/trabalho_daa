{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Processing**\n",
    "\n",
    "After Loading the data, we must now process it in order to be able to use it in our model. For this we will follow the following steps:\n",
    "1. Remove unnecessary columns\n",
    "2. Handle the Date column on both datasets and unify the format\n",
    "3. Join the datasets\n",
    "4. Handle the missing values or rows (dates that are not present in both datasets) if any\n",
    "5. Handle the categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_energy = pd.read_csv('datasets/energy.csv',na_filter=False, encoding = \"latin\")\n",
    "df_meteorology = pd.read_csv('datasets/meteorology.csv', na_filter=False, encoding = \"latin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop city_name, sea_level and grnd_level as they only have one unique value\n",
    "df_meteorology = df_meteorology.drop(['city_name', 'sea_level', 'grnd_level'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handle the Date column on both datasets and unify the format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal (kWh)</th>\n",
       "      <th>Horário Económico (kWh)</th>\n",
       "      <th>Autoconsumo (kWh)</th>\n",
       "      <th>Injeção na rede (kWh)</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274</td>\n",
       "      <td>Very High</td>\n",
       "      <td>2021-11-05 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Normal (kWh) Horário Económico (kWh) Autoconsumo (kWh)  \\\n",
       "901          0.0                     0.0             0.274   \n",
       "\n",
       "    Injeção na rede (kWh)             datetime  \n",
       "901             Very High  2021-11-05 13:00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert columns to unified format\n",
    "df_energy['datetime'] = pd.to_datetime(df_energy['Data'] + ' ' + df_energy['Hora'].astype(str) + ':00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Drop the original 'Data' and 'Hora' columns\n",
    "df_energy = df_energy.drop(['Data', 'Hora'], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_energy.iloc[901].to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meteorology dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>2021-10-04 09:00:00</td>\n",
       "      <td>14.03</td>\n",
       "      <td>13.84</td>\n",
       "      <td>13.34</td>\n",
       "      <td>14.54</td>\n",
       "      <td>1023</td>\n",
       "      <td>90</td>\n",
       "      <td>2.07</td>\n",
       "      <td></td>\n",
       "      <td>69</td>\n",
       "      <td>broken clouds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime   temp feels_like temp_min temp_max pressure  \\\n",
       "801  2021-10-04 09:00:00  14.03      13.84    13.34    14.54     1023   \n",
       "\n",
       "    humidity wind_speed rain_1h clouds_all weather_description  \n",
       "801       90       2.07                 69       broken clouds  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert columns to unified format\n",
    "df_meteorology['dt_iso'] = pd.to_datetime(df_meteorology['dt_iso'], format='%Y-%m-%d %H:%M:%S %z UTC')\n",
    "df_meteorology['dt_iso'] = df_meteorology['dt_iso'].dt.tz_localize(None)\n",
    "\n",
    "# Rename the column to 'datetime'\n",
    "df_meteorology = df_meteorology.rename(columns={\"dt_iso\": \"datetime\"})\n",
    "\n",
    "# We can also drop the 'dt' column as it is redundant\n",
    "df_meteorology = df_meteorology.drop(['dt'], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_meteorology.iloc[801].to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the dataframes by datetime so we can detect any time skips\n",
    "df_energy = df_energy.sort_values(by=['datetime'])\n",
    "df_meteorology = df_meteorology.sort_values(by=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irregular time intervals in df_en:\n",
      "0   NaT\n",
      "Name: datetime, dtype: timedelta64[ns]\n",
      "\n",
      "\n",
      "Irregular time intervals in df_me:\n",
      "0   NaT\n",
      "Name: datetime, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "time_diff_en = df_energy['datetime'].diff()\n",
    "time_diff_me = df_meteorology['datetime'].diff()\n",
    "\n",
    "# Print the irregular time intervals\n",
    "irregularities_en = time_diff_en[time_diff_en != '0 days 01:00:00']\n",
    "irregularities_me = time_diff_me[time_diff_me != '0 days 01:00:00']\n",
    "print(\"Irregular time intervals in df_en:\")\n",
    "print(irregularities_en)\n",
    "print(\"\\n\")\n",
    "print(\"Irregular time intervals in df_me:\")\n",
    "print(irregularities_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rename columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11016 entries, 0 to 11015\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   Normal (kWh)             11016 non-null  float64       \n",
      " 1   Horário Económico (kWh)  11016 non-null  float64       \n",
      " 2   Autoconsumo (kWh)        11016 non-null  float64       \n",
      " 3   Injection                11016 non-null  object        \n",
      " 4   datetime                 11016 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(1)\n",
      "memory usage: 430.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Rename Injeção na rede (kWh) to Injection\n",
    "df_energy = df_energy.rename(columns={'Injeção na rede (kWh)': 'Injection'})\n",
    "\n",
    "df_energy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Join the datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_join_merged_df = pd.merge(df_energy, df_meteorology, on='datetime', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal (kWh)               672\n",
       "Horário Económico (kWh)    672\n",
       "Autoconsumo (kWh)          672\n",
       "Injection                  672\n",
       "datetime                     0\n",
       "temp                         0\n",
       "feels_like                   0\n",
       "temp_min                     0\n",
       "temp_max                     0\n",
       "pressure                     0\n",
       "humidity                     0\n",
       "wind_speed                   0\n",
       "rain_1h                      0\n",
       "clouds_all                   0\n",
       "weather_description          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_join_merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the datetime data exhibited no irregularities, the additional entries present in the Weather dataset but not in the Energy dataset can be attributed to the Weather dataset containing data from days before or after the Energy dataset's first or last entry, respectively. A manual analysis of the dataset reveals that the Weather dataset includes entries starting from 2021-09-01, while the Energy dataset commences from 2021-09-29. Consequently, there are two possible paths we can take: \n",
    "- The first is to exclude entries from the Weather dataset that precede 2021-09-29, as they will not contribute to the modeling process. In order to achieve this we will do an Inner Join between the two datasets on the datetime column, and the resulting dataset will be the one we use going forward.\n",
    "- The alternative is to keep the entries from the Weather dataset that precede 2021-09-29, and fill the missing values with the mean of the values from the previous day. This will allow us to use the data from the Weather dataset in the modeling process, but it will also introduce a bias in the data. In order to achieve this we will keep this Outer Join between the two datasets and make the necessary modifications.\n",
    "\n",
    "Therefore we will be training the models on two different datasets, one with the Inner Join and one with the Outer Join."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
